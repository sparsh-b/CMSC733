{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKARgqUEG9Nd"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cee3vAcLrOs0"
      },
      "outputs": [],
      "source": [
        "## Import necessary libraries here\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "from google.colab.patches import cv2_imshow\n",
        "import itertools\n",
        "import copy\n",
        "from math import sqrt\n",
        "import math\n",
        "from scipy.linalg import sqrtm\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE_F4Hf5jUif"
      },
      "source": [
        "# Image stitching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSpCKlC_jcde"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1ev7ax-ujoOAdfy4a5XqlERXTeSOX1WQq\" width=\"800\"/>\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this problem, you will implement an algorithm for automatically estimating the fundamental matrix F using RANSAC and the normalized 8-point algorithm. \n",
        "\n",
        "Image Stitching Algorithm Overview\n",
        "1. Detect keypoints\n",
        "2. Match keypoints\n",
        "3. Estimate homography with matched keypoints (using RANSAC)\n",
        "4. Combine images\n",
        "\n",
        "**Note:**  Do not use existing image stitching code, such as found on the web, and OpenCV."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EOoxrZurmYz"
      },
      "source": [
        "## Data\n",
        "\n",
        "**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tspp6CyMroUC",
        "outputId": "969c4cab-5217-4d3d-ccb1-a053bd0c43d0"
      },
      "outputs": [],
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "!gdown 1fnD0hJ8-_Rngsc-m96ghKtdZAMf0VTjy\n",
        "!unzip \"/content/hill.zip\" -d \"/content/hill\"\n",
        "\n",
        "!gdown 1v2BFVMV0McuD5BstLvDmo1U9MrFAByS5\n",
        "!unzip \"/content/tv.zip\" -d \"/content/tv\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlVZP1tvMAxH"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9gRD27_MCDo"
      },
      "outputs": [],
      "source": [
        "def plot_matches(img1, img2, keypoints_1, keypoints_2, matches):\n",
        "  combined_img = np.hstack((img1, img2))\n",
        "  img1_cols = img1.shape[1]\n",
        "  colors = [(0, 0, 255), (0, 255,0), (255,0,0), (255,255,0), (0,255,255), (255,0,255)]\n",
        "  j=0\n",
        "  for i in range(len(matches)):\n",
        "    pt1 = (round(tuple(keypoints_1[matches[i][0]].pt)[0])          , round(tuple(keypoints_1[matches[i][0]].pt)[1]))\n",
        "    pt2 = (round(tuple(keypoints_2[matches[i][1]].pt)[0])+img1_cols, round(tuple(keypoints_2[matches[i][1]].pt)[1]))\n",
        "    j %= len(colors)\n",
        "    color = colors[j]\n",
        "    j+=1\n",
        "    combined_img = cv2.line(combined_img, pt1, pt2, color, 1)\n",
        "  cv2_imshow(combined_img)\n",
        "\n",
        "def est_homography(src, dest):\n",
        "    N = src.shape[0]\n",
        "    if N != dest.shape[0]:\n",
        "        raise ValueError(\"src and diff should have the same dimension\")\n",
        "    src_h = np.hstack((src, np.ones((N, 1))))\n",
        "    A = np.array([np.block([[src_h[n], np.zeros(3), -dest[n, 0] * src_h[n]],\n",
        "                            [np.zeros(3), src_h[n], -dest[n, 1] * src_h[n]]])\n",
        "                  for n in range(N)])\n",
        "    A = A.reshape(2 * N, 9)\n",
        "    [_, _, V] = np.linalg.svd(A)\n",
        "    return V.T[:, 8].reshape(3, 3)\n",
        "\n",
        "def apply_homography(H, src):\n",
        "    src_h = np.hstack((src, np.ones((src.shape[0], 1))))\n",
        "    dest =  src_h @ H.T\n",
        "    if dest[:,[2]].any() == 0:\n",
        "      print('divide by zero')\n",
        "    return (dest / dest[:,[2]])[:,0:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBhvHlseN_6F"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBu2Tu987E7h"
      },
      "outputs": [],
      "source": [
        "def compare(x):\n",
        "  return x[0]\n",
        "\n",
        "def compute_2nn_ratio(Descriptor1, Descriptor2):\n",
        "  diff = Descriptor2 - Descriptor1\n",
        "  dist = np.expand_dims(np.linalg.norm(diff, axis=1), axis=1)\n",
        "  temp = np.expand_dims([t for t in range(dist.shape[0])], axis=1)\n",
        "  dist = np.concatenate((dist, temp), axis=1).tolist()\n",
        "  dist.sort(key=compare)\n",
        "  return dist[0][0]/dist[1][0], int(dist[0][1])\n",
        "\n",
        "def detect_keypoints_and_find_matches(img1, img2, display):\n",
        "  sift = cv2.xfeatures2d.SIFT_create()\n",
        "  keypoints_1, descriptors_1 = sift.detectAndCompute(img1,None)\n",
        "  keypoints_2, descriptors_2 = sift.detectAndCompute(img2,None)\n",
        "  matches = []\n",
        "  threshold_2NN = 0.45 #0.45\n",
        "  for i in range(len(keypoints_1)):\n",
        "    ratio, closest_match = compute_2nn_ratio(descriptors_1[i], descriptors_2)\n",
        "    if ratio < threshold_2NN:\n",
        "      matches.append([i, closest_match])\n",
        "  print('Number of matches =', len(matches))\n",
        "  if display:\n",
        "    plot_matches(img1, img2, keypoints_1, keypoints_2, matches)\n",
        "  return matches, keypoints_1, keypoints_2\n",
        "\n",
        "def normalize__(img1_shape, img2_shape, matches, keypoints_1, keypoints_2):\n",
        "  x1 = [i for i in range(img1_shape[1])]\n",
        "  y1 = [i for i in range(img1_shape[0])]\n",
        "  x2 = [i for i in range(img2_shape[1])]\n",
        "  y2 = [i for i in range(img2_shape[0])]\n",
        "  (mean_x1, std_x1, mean_y1, std_y1) = [np.mean(x1), np.std(x1), np.mean(y1), np.std(y1)]\n",
        "  (mean_x2, std_x2, mean_y2, std_y2) = [np.mean(x2), np.std(x2), np.mean(y2), np.std(y2)]\n",
        "  T1 = np.array([[1/std_x1,     0   , -mean_x1/std_x1],\n",
        "                [    0    , 1/std_y1, -mean_y1/std_y1],\n",
        "                [    0    ,     0   ,        1       ]])\n",
        "  T2 = np.array([[1/std_x2,     0   , -mean_x2/std_x2],\n",
        "                [    0    , 1/std_y2, -mean_y2/std_y2],\n",
        "                [    0    ,     0   ,        1       ]])\n",
        "  \n",
        "  normalized_coords1 = []\n",
        "  normalized_coords2 = []\n",
        "  for i in range(len(matches)):\n",
        "    (temp1, temp2) = [list(keypoints_1[matches[i][0]].pt), list(keypoints_2[matches[i][1]].pt)]\n",
        "    temp1.append(1)\n",
        "    temp2.append(1)\n",
        "    (temp1, temp2) = [np.array(temp1), np.array(temp2)]\n",
        "    temp1 = T1 @ temp1\n",
        "    temp2 = T2 @ temp2\n",
        "    normalized_coords1.append(temp1)\n",
        "    normalized_coords2.append(temp2)\n",
        "\n",
        "  normalized_coords1 = np.array(normalized_coords1)\n",
        "  normalized_coords2 = np.array(normalized_coords2)\n",
        "  xy1_ = normalized_coords1[:, :-1]\n",
        "  xy2_ = normalized_coords2[:, :-1]\n",
        "  return xy1_, xy2_, T1, T2\n",
        "\n",
        "\n",
        "def stitch_2_images(img1, img2, display):\n",
        "  matches, keypoints_1, keypoints_2 = detect_keypoints_and_find_matches(img1, img2, display)\n",
        "  xy1_, xy2_, T1, T2 = normalize__(img1.shape, img2.shape, matches, keypoints_1, keypoints_2)\n",
        "  distance_threshold = 0.01 #0.01\n",
        "  max_num_inliers = -1\n",
        "  for _ in range(1000):\n",
        "    rand_indices = random.sample(range(0, xy1_.shape[0]), 4)\n",
        "    subset_xy2_ = xy2_[tuple([rand_indices])]\n",
        "    subset_xy1_ = xy1_[tuple([rand_indices])]\n",
        "    H_norm = est_homography(subset_xy1_, subset_xy2_)\n",
        "    xy1_homo = apply_homography(H_norm, xy1_)\n",
        "    diff = xy2_ - xy1_homo\n",
        "    distances = np.linalg.norm(diff, axis=1)\n",
        "    distances[distances<=distance_threshold] = -1\n",
        "    distances[distances>distance_threshold] = 0\n",
        "    num_inliers = np.sum(distances) / -1\n",
        "    if max_num_inliers < num_inliers:\n",
        "      max_num_inliers = num_inliers\n",
        "      max_inlier_comb = tuple(np.arange(xy2_.shape[0])[distances==-1])\n",
        "\n",
        "  print('Max number of inliers =', max_num_inliers)\n",
        "  subset_xy1_ = xy1_[tuple([max_inlier_comb])]\n",
        "  subset_xy2_ = xy2_[tuple([max_inlier_comb])]\n",
        "  H_norm = est_homography(subset_xy1_, subset_xy2_)\n",
        "  H = np.linalg.inv(T2) @ H_norm @ T1\n",
        "  print('De-normalized Homography:\\n', H)\n",
        "  xy1 = np.mgrid[0:img1.shape[1]:0.25, 0:img1.shape[0]:0.25]\n",
        "  xy1 = xy1.reshape((2, -1))\n",
        "  xy1 = np.transpose(xy1)\n",
        "\n",
        "  xy1_homo = apply_homography(H, xy1)\n",
        "  combined_img = np.zeros((img1.shape[0], img1.shape[1]+img2.shape[1], 3)) # define the size of new canvas\n",
        "  combined_img[:, -img2.shape[1]:, :] = img2\n",
        "  counter_rows = 0\n",
        "  counter_cols_L = 0\n",
        "  counter_cols_R = 0\n",
        "  counter_rows_cols = 0\n",
        "  for i in range(xy1_homo.shape[0]):\n",
        "    new_row = int(xy1_homo[i][1])\n",
        "    new_col = int(xy1_homo[i][0]+img1.shape[1])\n",
        "    if (new_row < 0) or (new_row > img1.shape[0]-1) or (new_col > img1.shape[1]+img2.shape[1]-1) or (new_col < 0):\n",
        "      continue\n",
        "    combined_img[new_row, new_col] = img1[int(xy1[i][1]), int(xy1[i][0])]\n",
        "  combined_img = combined_img.astype(np.uint8)\n",
        "  if display:\n",
        "    cv2_imshow(combined_img)\n",
        "  return combined_img\n",
        "\n",
        "\n",
        "# img1 = cv2.imread('/content/tv/1.jpg')\n",
        "# img2 = cv2.imread('/content/tv/2.jpg')\n",
        "# img3 = cv2.imread('/content/tv/3.jpg')\n",
        "img1 = cv2.imread('/content/hill/1.JPG')\n",
        "img2 = cv2.imread('/content/hill/2.JPG')\n",
        "img3 = cv2.imread('/content/hill/3.JPG')\n",
        "stitched_12 = stitch_2_images(img1, img2, True)\n",
        "stitched_123 = stitch_2_images(stitched_12, img3, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCSoLSQON2yj"
      },
      "source": [
        "### Write-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGGINt3MCKK6"
      },
      "source": [
        "- 1) Removing incorrect matches with RANSAC:\n",
        "  - RANSAC involves rejecting outliers. It does this by randomly sampling N samples from M (M>N) data points (here, match pairs) & fitting an equation to those N samples. Then, all the M data points are substituted in the above fitted equation & those data points which don't satisfy the equation upto a threshold distance are considered as incorrect matches (outliers) & they are removed.\n",
        "  - This process is repeated for many iterations & the iteration which has the least number of outliers is selected to get the final estimate for the equation.\n",
        "\n",
        "- 2) The following are the de-normalized Homography matrices for stitching (i) the 1st hill image with the 2nd hill image & (ii) the stitched 1st & 2nd hill image with the 3rd hill image:\n",
        "  - <img src=\"https://drive.google.com/uc?id=1z0ipA7VsynFlsna9DXdj_0Q5Lor8tsRu\" width=\"400\"/>\n",
        "  - <img src=\"https://drive.google.com/uc?id=1OAQtWGj9hDfdVMkJfm6a8GpRSPw4b-8V\" width=\"400\"/>\n",
        "\n",
        "- 3) Blended images:\n",
        "  - <img src=\"https://drive.google.com/uc?id=1zVbOac1xOpr8WYGUfwRDfqBL9ozW4KW5\"/>\n",
        "  - <img src=\"https://drive.google.com/uc?id=1qTLNd6yPPMlEbP5xhaOlQz01Tsr7zgGd\"/>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
