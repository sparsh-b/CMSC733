{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy_Iqu-qnIj3"
      },
      "outputs": [],
      "source": [
        "## Import necessary libraries here\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import copy\n",
        "import os\n",
        "import time\n",
        "%matplotlib inline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F6UrONbD4LcH"
      },
      "source": [
        "# Object Instance Recognition"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EGoM9Ra_4QLS"
      },
      "source": [
        "## Overview\n",
        "- This problem explores the Lowe-style object instance recognition.\n",
        "    - The ratio of the distances of a given feature-vector to its 1st nearest neighbor and to its 2nd nearest neighbor is used as thresholding function.\n",
        "- Expected Result\n",
        "<img src=\"https://drive.google.com/uc?id=1T5-qI0qPk2FHuesLIvWQ1jqRI9T9-WeC\" width=\"1000\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDy-8Y7Oj7kJ"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0AUhSYpj8ed"
      },
      "outputs": [],
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "!gdown 10ByzpFbB-z178VGjwmCwc95wInD8vpNM # SIFT Features\n",
        "!gdown 1KLWGMtDEMNNrmzd3Qezrs2-NQR52OfoU # Stop sign image 1\n",
        "!gdown 13y-o1vdGN6CqqPuUcgU7pIxODTxrYS7J # Stop sign image 1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gQW8iyjH_Ijd"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I3eiXvz_IGj"
      },
      "outputs": [],
      "source": [
        "def compare(x):\n",
        "  return x[0]\n",
        "\n",
        "img1 = cv2.imread('/content/stop1.jpg')\n",
        "img2 = cv2.imread('/content/stop2.jpg')\n",
        "\n",
        "## inside the sift are:\n",
        "## Descriptor1, Descriptor2: SIFT features from image 1 and image 2\n",
        "## Frame1, Frame2: position, scale, rotation of keypoints\n",
        "data = loadmat('/content/SIFT_features.mat')\n",
        "Frame1 = data['Frame1']\n",
        "Descriptor1 = data['Descriptor1']\n",
        "Frame2 = data['Frame2']\n",
        "Descriptor2 = data['Descriptor2']\n",
        "\n",
        "Frame1 = np.transpose(Frame1)\n",
        "Frame2 = np.transpose(Frame2)\n",
        "Descriptor1 = np.transpose(Descriptor1).astype('float32')\n",
        "Descriptor2 = np.transpose(Descriptor2).astype('float32')\n",
        "\n",
        "\n",
        "matches_NN = []\n",
        "matches_2NN = []\n",
        "threshold_NN = 120\n",
        "threshold_2NN = 0.548\n",
        "data_type = [['distance', 'float32'], ['idx', int]]\n",
        "for i in range(Descriptor1.shape[0]):\n",
        "  diff = Descriptor2 - Descriptor1[i]\n",
        "  dist = np.expand_dims(np.linalg.norm(diff, axis=1), axis=1)\n",
        "  temp = np.expand_dims([t for t in range(dist.shape[0])], axis=1)\n",
        "  dist = np.concatenate((dist, temp), axis=1).tolist()\n",
        "  dist.sort(key=compare)\n",
        "\n",
        "  if dist[0][0] < threshold_NN:\n",
        "    matches_NN.append([i, int(dist[0][1])])\n",
        "  if (dist[0][0]/dist[1][0]) < threshold_2NN:\n",
        "    matches_2NN.append([i, int(dist[0][1])])\n",
        "\n",
        "## Display the matched keypoints\n",
        "(rows1, cols1, _) = img1.shape\n",
        "(rows2, cols2, _) = img2.shape\n",
        "combined_img = np.zeros((max(rows1, rows2), cols1+cols2, 3))\n",
        "combined_img[:rows1, :cols1, :] = img1\n",
        "combined_img[:, cols1:cols1+cols2, :] = img2\n",
        "combined_img2 = copy.copy(combined_img)\n",
        "\n",
        "print(len(matches_NN), len(matches_2NN))\n",
        "for match_NN in matches_NN:\n",
        "  combined_img = cv2.line(combined_img, (int(Frame1[match_NN[0]][0]), int(Frame1[match_NN[0]][1])), (int(Frame2[match_NN[1]][0])+cols1, int(Frame2[match_NN[1]][1])), (0, 255, 0), 2)\n",
        "\n",
        "for match_NN in matches_2NN:\n",
        "  combined_img2 = cv2.line(combined_img2, (int(Frame1[match_NN[0]][0]), int(Frame1[match_NN[0]][1])), (int(Frame2[match_NN[1]][0])+cols1, int(Frame2[match_NN[1]][1])), (0, 255, 0), 2)\n",
        "\n",
        "cv2_imshow(combined_img)\n",
        "cv2_imshow(combined_img2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D7ApiN9gAP6Z"
      },
      "source": [
        "## Write-up\n",
        "<!-- \n",
        "(5 pts) Display:\n",
        "\n",
        "1. the matches by thresholding nearest neighbor distances.\n",
        "\n",
        "2. the matches by thresholding the distance ratio. \n",
        "\n",
        "(5 pts) Describe the differences of (1) and (2). -->"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fEa_-lFkux7C"
      },
      "source": [
        "#### Results:\n",
        " - <u>Method-1:</u> Matches by thresholding nearest neighbor distances:\n",
        " - <img src=\"https://drive.google.com/uc?id=1LxXW19UoMUcZb0zmVWYnU1rJh5tREOGh\" align=\"center\"/>\n",
        " \n",
        " - <u>Method-2:</u> Matches by thresholding distance ratio:\n",
        " - <img src=\"https://drive.google.com/uc?id=1EJzAiMPLDfL5VSTBSlUtRp0bEGwdumvo\" align=\"center\"/>\n",
        "\n",
        "#### Comparison:\n",
        "  - The distance ratio method is better at telling apart close-looking but dissimilar features.\n",
        "  - It has a better False-Positive rate.\n",
        "  - It can be observed (as shown below) that the nearest neighbor distance method falsely matched 2 SIFT descriptors on the white border of the stop sign. But the distance ratio method didn't do such a mistake.\n",
        "  - <img src=\"https://drive.google.com/uc?id=10vRqvAc6b3J651YPGjcsmMzLKciIoufH\" align=\"center\"/>\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qWCfxrUA7LNb",
        "ZDy-8Y7Oj7kJ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
