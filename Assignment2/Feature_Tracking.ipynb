{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "uvkyHmVv1Xe7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy_Iqu-qnIj3"
      },
      "outputs": [],
      "source": [
        "## Import necessary libraries here\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import copy\n",
        "import os\n",
        "import time\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ftoiwAo45n5"
      },
      "source": [
        "# Feature Detection & Tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJikaY9ICDYH"
      },
      "source": [
        "## Overview\n",
        "\n",
        "- This problem involves implementing a corner detector and feature tracker that track features from a sequence of hotel images.\n",
        "- The below image on left shows the result of 1st part & the right image shows the result of the 2nd part.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=11Vc092sR0YPG68Jvca724951CrrEGb31\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR0sjl-f6qkm"
      },
      "source": [
        "## Data\n",
        "\n",
        "**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uWzKA6i68ls"
      },
      "outputs": [],
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "if not os.path.exists('/content/part1_images/hotel.seq41.png'):\n",
        "  !gdown 1fT0H-FbbDZnjMfCJHZcscpcwAXHhGgNw\n",
        "  !unzip \"/content/part1_images.zip\" -d \"/content/\"\n",
        "  !gdown 1r-Pdino6MRLCEWX_sQOgd8D5AVsRc7Ym\n",
        "  # Load Initial Key Points\n",
        "  data = loadmat('/content/initial_keypoints.mat')\n",
        "  X0 = data['Xo']\n",
        "  Y0 = data['Yo']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_Pd1s5uL2Bg"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gESONvcFL4y0"
      },
      "outputs": [],
      "source": [
        "def readImages(folder, num_images):\n",
        "  arr_images = []\n",
        "  for i in range(num_images):\n",
        "    arr_images.append(cv2.imread(f'{folder}hotel.seq{i}.png'))\n",
        "  return np.array(arr_images, dtype=np.float32)\n",
        "\n",
        "def compute_H(patch): #Given a patch, compute the 2nd moment matrix within the patch\n",
        "  Ix = patch[:, 1:] - patch[:, :-1]\n",
        "  Iy = patch[1:, :] - patch[:-1, :]\n",
        "  Ix = Ix[:-1, :]\n",
        "  Iy = Iy[:, :-1]\n",
        "  Ix_sq = np.sum(np.square(Ix))\n",
        "  Iy_sq = np.sum(np.square(Iy))\n",
        "  Ix_Iy = np.sum(Ix * Iy)\n",
        "  H = np.array([[Ix_sq, Ix_Iy], [Ix_Iy, Iy_sq]])\n",
        "  return H, Ix, Iy\n",
        "\n",
        "def pad_the_patch(patch): #pad the image by replicating the last row & last column. Resultant patch will have 1 additional row & column than the original one.\n",
        "  patch = np.concatenate((patch, np.expand_dims(patch[:, -1], axis=1)), axis=1)\n",
        "  patch = np.concatenate((patch, np.expand_dims(patch[-1, :], axis=0)), axis=0)\n",
        "  return patch\n",
        "\n",
        "# read all 51 sequences of images\n",
        "folder = '/content/part1_images/'\n",
        "im = readImages(folder, 51)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7ouOF_UlTKF"
      },
      "source": [
        "## 1.1 Keypoint Selection\n",
        "\n",
        "- For the first frame in the sequemce, the second moment matrix is used to locate strong corners to use as keypoints.\n",
        "- These points will be tracked throughout the sequence in the second part of the problem.\n",
        "- A fine-tuned threshold is choosen so that edges and noisy patches are ignored.\n",
        "- Then a local non-maxima suppression (NMS) is performed over a 5x5 window centered at each point.\n",
        "- This gave several hundred good points to track."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efy0NyPjo3y3"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeXJU9eHmzMb"
      },
      "outputs": [],
      "source": [
        "def apply_NMS(f_values, window_size):\n",
        "  '''\n",
        "  Apply local Non-Maxima Suppression:\n",
        "  1) Slide a 5x5 window all over the image.\n",
        "  2) Retain the center of those 5x5 windows as keypoints in which the center pixel is the local maxima in that window.\n",
        "  '''\n",
        "  (rows, cols) = f_values.shape\n",
        "  half_size = window_size//2\n",
        "  keypoints = np.zeros((rows, cols))\n",
        "  for i in range(half_size, rows-half_size):\n",
        "    for j in range(half_size, cols-half_size):\n",
        "      patch = f_values[i-half_size:i+half_size+1, j-half_size:j+half_size+1]\n",
        "      uniq, counts = np.unique(patch, return_counts=True)\n",
        "      if counts[-1] > 1:\n",
        "        continue\n",
        "      if uniq[-1] == f_values[i, j]:\n",
        "        keypoints[i, j] = 255\n",
        "  return keypoints\n",
        "\n",
        "def getKeypoints(img, tau):\n",
        "  '''\n",
        "  Detecting keypoints using Harris corner criterion\n",
        "  img: input image\n",
        "  tau: threshold \n",
        "  \n",
        "  output: (N,2) array of [x,y] keypoints (x & y are 0-indexed with upper left pixel of the image being (0,0). i.e, OpenCV frame convention).\n",
        "  '''\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  (rows, cols) = img.shape\n",
        "  window_size = 5 \n",
        "  half_size = window_size//2\n",
        "  f_values = np.zeros_like(img)\n",
        "  for i in range(half_size, rows-half_size):\n",
        "    for j in range(half_size, cols-half_size):\n",
        "      patch = img[i-half_size:i+half_size+1, j-half_size:j+half_size+1]\n",
        "      padded_patch = pad_the_patch(patch)\n",
        "      H, _, _ = compute_H(padded_patch)\n",
        "      harris_operator = np.linalg.det(H) / np.trace(H)\n",
        "      if harris_operator>tau:\n",
        "        f_values[i, j] = harris_operator\n",
        "  f_values = f_values/np.amax(f_values)\n",
        "  keypoints = apply_NMS(f_values, window_size)\n",
        "  print('Number of keypoints selected:', np.sum(keypoints)/255)\n",
        "\n",
        "  keypoints_opencv = []\n",
        "  for i in range(half_size, rows-half_size):\n",
        "    for j in range(half_size, cols-half_size):\n",
        "      if keypoints[i,j] == 255:\n",
        "        keypoints_opencv.append([j, i])\n",
        "  return keypoints_opencv\n",
        "\n",
        "tau = 3.15*255\n",
        "# tau is tuned as below: <tau> -> <number of keypoints it gave>\n",
        "# 0.17->1102 0.25->1061 0.55->991 0.85->865 0.95->813 1.15->740 3.15->201\n",
        "keypoints_opencv = getKeypoints(im[0], tau)\n",
        "\n",
        "# add plots for the write-up\n",
        "display_img = cv2.cvtColor(im[0], cv2.COLOR_BGR2GRAY)\n",
        "(rows, cols) = display_img.shape\n",
        "display_img = cv2.cvtColor(display_img, cv2.COLOR_GRAY2BGR)\n",
        "for key_pt in keypoints_opencv:\n",
        "  display_img = cv2.circle(display_img, (key_pt[0], key_pt[1]), radius=3, color=(0, 255, 0), thickness=-1)\n",
        "cv2_imshow(display_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmN8MtK2mOUz"
      },
      "source": [
        "### Write-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I06DhqYI4YI7"
      },
      "source": [
        "#### Algorithm to get KeyPoints:\n",
        "- A 5x5 window is slid on the grayscale image (with a stride of 1) & the 2nd moment matrix `H` is calculated using the below formula:\n",
        "\n",
        "  - <img src=\"https://drive.google.com/uc?id=1_W_a9FwMjDlyTWAXLOrXvsFBcIEeZfli\" height=400 align=\"center\"/>\n",
        "  - where:\n",
        "    - `i_x` & `i_y` are the gradients in x & y directions.\n",
        "    - The gradient `i_x` is calculated as `intensity of pixel (p+1,q) - intensity of pixel (p,q)`\n",
        "    - The summations in the formulas for `A`,`B`&`C` run over the 5x5 window.\n",
        "\n",
        "- The harris operator is calculated by the below formula:\n",
        "  - <img src=\"https://drive.google.com/uc?id=1gBxEZQ1yttjpwMHdpNpbFhq4kZlQJPUr\" height=200 align=\"center\"/>\n",
        "  - It is calculated over all the 5x5 windows.\n",
        "- ##### Thresholding:\n",
        "  - Those pixels for which harris operator yielded a value of greater than `tau` were marked as potential keypoints & the rest are discarded.\n",
        "  - `tau = 803.25` was selected after a bit of tuning.\n",
        "- ##### Normalization:\n",
        "  - Then, the resultant harris operator matrix (of the same size as image) is divided by its maximum value.\n",
        "- Finally, non-maxima suppression is done (in the below way):\n",
        "  - If a pixel is strictly greater than every other pixel in the 5x5 neighborhood centered around it, it is retained. Else, it is discarded.\n",
        "- Note:\n",
        "  - No padding is done on the original image.\n",
        "  - Due to this, no keypoints will be detected in the `window_size//2` = 2 columns or rows along the border.\n",
        "\n",
        "#### Visualization of Keypoints detected:\n",
        "- The below image shows the final keypoints obtained by following the above method.\n",
        "- `201` keypoints were selected for `tau = 803.25`.\n",
        "- <img src=\"https://drive.google.com/uc?id=1thCSU_TWlgDcGmzrcDMjZ43CszK2cQl3\" align=\"center\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0-XMmadpALk"
      },
      "source": [
        "## 1.2 Feature Tracking\n",
        "\n",
        "- Apply the Kanade-Lucas-Tomasi tracking procedure to track the keypoints found in part 1 throughout the hotel sequence. \n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1JsyiJlWH6xnXW0Jf0rTHkRoeNn2Mo-Hm\" width=\"500\"/>\n",
        "\n",
        "- Some keypoints will move out of the image frame over the course of the sequence.\n",
        "- Portions of the trajectories of such points which fall outside the image frame are discarded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnjkdkuWtzo9"
      },
      "outputs": [],
      "source": [
        "def trackPoints(pt_x, pt_y, im, ws, out_of_bound_pts):\n",
        "  '''\n",
        "  Tracking initial points (pt_x, pt_y) across the image sequence\n",
        "  Outputs:\n",
        "    track_x: [Number of keypoints] x [2]\n",
        "    track_y: [Number of keypoints] x [2]\n",
        "  '''\n",
        "  pt_x = pt_x.astype('float32')\n",
        "  pt_y = pt_y.astype('float32')\n",
        "  N = np.prod(pt_x.shape)\n",
        "  nim = len(im)\n",
        "  track_x = np.zeros((N, nim))\n",
        "  track_y = np.zeros((N, nim))\n",
        "  track_x[:,0] = pt_x\n",
        "  track_y[:,0] = pt_y\n",
        "  if len(im.shape) == 4:\n",
        "    im = im[:, :, :, 0].astype('float32')\n",
        "  else:\n",
        "    input('No resizing is being done. Continue?')\n",
        "  for t in range(nim-1):\n",
        "    track_x[:, t+1], track_y[:, t+1] = getNextPoints(track_x[:, t], track_y[:, t], im[t,:,:], im[t+1,:,:], ws, out_of_bound_pts)\n",
        "\n",
        "  return np.concatenate((np.expand_dims(track_x, axis=2), np.expand_dims(track_y, axis=2)), axis=2)\n",
        "\n",
        "def getNextPoints(xs, ys, im1, im2, ws, out_of_bound_pts):\n",
        "  '''\n",
        "  Iterative Lucas-Kanade feature tracking\n",
        "  x,  y : initialized keypoint position in im2\n",
        "  ws: patch window size\n",
        "\n",
        "  output: tracked keypoint positions in im2\n",
        "  '''\n",
        "  threshold = 0.5\n",
        "  x_next_frame = []\n",
        "  y_next_frame = []\n",
        "  (rows, cols) = im1.shape\n",
        "  for idx, (x,y) in enumerate(zip(xs, ys)):\n",
        "    u = 10\n",
        "    v = 10\n",
        "    x_dash = copy.copy(x)\n",
        "    y_dash = copy.copy(y)\n",
        "    patch = cv2.getRectSubPix(im1, (ws,ws), (x,y))\n",
        "    H, Ix, Iy = compute_H(pad_the_patch(patch))\n",
        "    while (u>threshold) or (v>threshold):\n",
        "      It = cv2.getRectSubPix(im2, (ws,ws), (x_dash,y_dash)) - cv2.getRectSubPix(im1, (ws,ws), (x,y))\n",
        "      Ix_It = -1 * (np.sum(Ix*It))\n",
        "      Iy_It = -1 * (np.sum(Iy*It))\n",
        "      b = [Ix_It, Iy_It] # To solve ax=b, a=H & b is this matrix\n",
        "      try:\n",
        "        [u, v] = np.linalg.solve(H, b)\n",
        "      except:\n",
        "        print(np.linalg.det(H))\n",
        "        input('stopping')\n",
        "      new_x_dash = x_dash + u\n",
        "      new_y_dash = y_dash + v\n",
        "      if new_y_dash<0 or new_y_dash>rows-1 or new_x_dash<0 or new_x_dash>cols-1:\n",
        "        out_of_bound_pts.append(idx)\n",
        "        break\n",
        "      else:\n",
        "        x_dash = new_x_dash\n",
        "        y_dash = new_y_dash\n",
        "    x_next_frame.append(x_dash)\n",
        "    y_next_frame.append(y_dash)\n",
        "  return x_next_frame, y_next_frame\n",
        "\n",
        "ws = 7\n",
        "keypoints_list = copy.copy(np.array(keypoints_opencv))\n",
        "out_of_bound_pts = []\n",
        "tracked_pts = trackPoints(pt_x=keypoints_list[:,0], pt_y=keypoints_list[:,1], im=im, ws=ws, out_of_bound_pts=out_of_bound_pts)\n",
        "\n",
        "# plot your results\n",
        "display_img1 = copy.copy(im[0])\n",
        "display_img2 = copy.copy(im[0])\n",
        "display_img3 = copy.copy(im[0])\n",
        "rand_20_tracked_pts = np.random.permutation(np.arange(tracked_pts.shape[0]))[:20]\n",
        "for i in range(tracked_pts.shape[0]):\n",
        "  tracked_pt = tracked_pts[i]\n",
        "  display_img1 = cv2.circle(display_img1, (int(tracked_pt[0][0]), int(tracked_pt[0][1])), radius=2, color=(0, 255, 0), thickness=-1)\n",
        "  display_img1 = cv2.circle(display_img1, (int(tracked_pt[1][0]), int(tracked_pt[1][1])), radius=2, color=(0, 0, 255), thickness=-1)\n",
        "  if i in rand_20_tracked_pts:\n",
        "    for consec_frame_pts in tracked_pt:\n",
        "      display_img2 = cv2.circle(display_img2, (int(consec_frame_pts[0]), int(consec_frame_pts[1])), radius=2, color=(0, 0, 255), thickness=-1)\n",
        "  if i in out_of_bound_pts:\n",
        "    for consec_frame_pts in tracked_pt:\n",
        "      display_img3 = cv2.circle(display_img3, (int(consec_frame_pts[0]), int(consec_frame_pts[1])), radius=2, color=(0, 0, 255), thickness=-1)\n",
        "\n",
        "cv2_imshow(display_img1)\n",
        "cv2_imshow(display_img2)\n",
        "cv2_imshow(display_img3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O76508F1vH0_"
      },
      "source": [
        "### Write-up\n",
        "\n",
        "- The below results show the following:\n",
        "  - The keypoints at the first frame (as green) and the tracked keypoints at the second frame (as red) on the first frame of the sequence.\n",
        "  - The tracked path over the sequence of frames for 20 random keypoints.\n",
        "  - The points which have moved out of frame at some point along the sequence displayed on the first frame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHYhHqAM9R1l"
      },
      "source": [
        "- <img src=\"https://drive.google.com/uc?id=1kz8e8M1_RTHjEpZVAtdn8rew49lDUsbI\" height=400 align=\"center\"/>\n",
        "\n",
        "- <img src=\"https://drive.google.com/uc?id=1SbVyEFGKRlysslutuPNzkoj2rB0Y12c1\" height=400 align=\"center\"/>\n",
        "\n",
        "- <img src=\"https://drive.google.com/uc?id=1aRwEDLJ39ZgMVjPk8F1xHjHQ5UZEzRMG\" height=400 align=\"center\"/>\n"
      ]
    }
  ]
}