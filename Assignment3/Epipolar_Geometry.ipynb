{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKARgqUEG9Nd"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cee3vAcLrOs0"
      },
      "outputs": [],
      "source": [
        "## Import necessary libraries here\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "from google.colab.patches import cv2_imshow\n",
        "import itertools\n",
        "import copy\n",
        "from math import sqrt\n",
        "import math\n",
        "from scipy.linalg import sqrtm\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3j4FysdrPpj"
      },
      "source": [
        "# Part 1: Epipolar Geometry\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PQh0Alx6ibx"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this problem, you will implement an algorithm for automatically estimating homography with RANSAC. In the file matches.mat, we provide the detected Harris corners row-column positions in variables r1 c1 for the first image; variables r2 c2 for the second image; and the corresponding matched pairs in the variable matches.\n",
        "\n",
        "<!-- <img src=\"https://drive.google.com/uc?id=1Tr723u5OXmwkd4RDmu9z886ITJU9j1cL&export=download\" width=\"800\"/> -->\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1cCT_YU4xp-jRqh1dfoW5JE6MIZH-DDwP\" width=\"800\"/>\n",
        "\n",
        "The outline of the normalized 8-point algorithm:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1rw0Y7XOfqKhcNj2boJIWKJYje2a7mHGd\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhMdiMNjB9R7"
      },
      "source": [
        "### Data\n",
        "\n",
        "**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LNhf2S4CAIk",
        "outputId": "233360b4-9881-4b4e-ac81-f3ffab0c0f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cn3_SscjlLrf4BzUWe8MV-XqMqBY4Nj_\n",
            "To: /content/Part1_data.zip\n",
            "\r\n",
            "  0% 0.00/157k [00:00<?, ?B/s]\r\n",
            "100% 157k/157k [00:00<00:00, 77.2MB/s]\n",
            "Archive:  /content/Part1_data.zip\n",
            "   creating: /content/Part1_data/\n",
            "  inflating: /content/Part1_data/chapel00.png  \n",
            "  inflating: /content/Part1_data/chapel01.png  \n",
            "  inflating: /content/Part1_data/matches.mat  \n"
          ]
        }
      ],
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "!gdown 1cn3_SscjlLrf4BzUWe8MV-XqMqBY4Nj_\n",
        "!unzip \"/content/Part1_data.zip\" -d \"/content/\"\n",
        "# Load Matches\n",
        "data = loadmat('/content/Part1_data/matches.mat')\n",
        "r1 = data['r1']\n",
        "r2 = data['r2']\n",
        "c1 = data['c1']\n",
        "c2 = data['c2']\n",
        "matches = data['matches']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JTA_rZ4y_V8"
      },
      "outputs": [],
      "source": [
        "# Load Keypoints\n",
        "x1 = c1[matches[:,0]-1]\n",
        "y1 = r1[matches[:,0]-1]\n",
        "x2 = c2[matches[:,1]-1]\n",
        "y2 = r2[matches[:,1]-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjIGNyapNU_4"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lS5zihq7NRjh"
      },
      "outputs": [],
      "source": [
        "def normalize(x, y):\n",
        "  # Function: find the transformation to make it zero mean and the variance as sqrt(2)\n",
        "  std_x = np.std(x)\n",
        "  std_y = np.std(y)\n",
        "  mean_x = np.mean(x)\n",
        "  mean_y = np.mean(y)\n",
        "  T = np.array([[1/std_x,     0  , -mean_x/std_x],\n",
        "                [    0  , 1/std_y, -mean_y/std_y],\n",
        "                [    0  ,     0  ,      1       ]])\n",
        "  normalized_coords = []\n",
        "  for i in range(x.shape[0]):\n",
        "    temp = np.matmul(T, np.array([x[i], y[i], 1], dtype=object))\n",
        "    normalized_coords.append([temp[0][0], temp[1][0], temp[2][0]])\n",
        "  normalized_coords = np.array(normalized_coords)\n",
        "  normalized_x = normalized_coords[:, 0]\n",
        "  normalized_y = normalized_coords[:, 1]\n",
        "  return normalized_x, normalized_y, T\n",
        "  \n",
        "def ransacF(x1, y1, x2, y2, do_normalization=True, T1=None, T2=None):\n",
        "  if do_normalization:\n",
        "    # Find normalization matrix & Transform point set 1 and 2\n",
        "    x1, y1, T1 = normalize(x1, y1)\n",
        "    x2, y2, T2 = normalize(x2, y2)\n",
        "  # RANSAC based 8-point algorithm\n",
        "  threshold = 0.1\n",
        "  max_num_inliers = -1\n",
        "  num_iters = 0\n",
        "  rand_indices = [i for i in range(x1.shape[0])]\n",
        "  random.shuffle(rand_indices)\n",
        "  for subset in itertools.combinations(rand_indices, 8):\n",
        "    num_iters += 1\n",
        "    if num_iters>1400:\n",
        "      break\n",
        "    x1_subset = x1[tuple([subset])]\n",
        "    y1_subset = y1[tuple([subset])]\n",
        "    x2_subset = x2[tuple([subset])]\n",
        "    y2_subset = y2[tuple([subset])]\n",
        "    F = computeF(x1_subset,y1_subset,x2_subset,y2_subset)\n",
        "    num_inliers, distances = getInliers(x1, y1, x2, y2, F, threshold)\n",
        "    if num_inliers > max_num_inliers:\n",
        "      inlier_indices = tuple(np.arange(x1.shape[0])[distances==-1])\n",
        "      max_num_inliers = num_inliers\n",
        "      max_inlier_comb = inlier_indices \n",
        "  \n",
        "  print('Number of iterations =', num_iters)\n",
        "  print('Number of inliers =', max_num_inliers)\n",
        "  x1_subset = x1[tuple([max_inlier_comb])]\n",
        "  y1_subset = y1[tuple([max_inlier_comb])]\n",
        "  x2_subset = x2[tuple([max_inlier_comb])]\n",
        "  y2_subset = y2[tuple([max_inlier_comb])]\n",
        "  F_norm = computeF(x1_subset,y1_subset,x2_subset,y2_subset)\n",
        "  F = np.matmul(T1.T, np.matmul(F_norm, T2))\n",
        "  return F, max_inlier_comb\n",
        "\n",
        "def getInliers(x1, y1, x2, y2, F, threshold):\n",
        "  # Function: implement the criteria checking inliers.\n",
        "  distances = []\n",
        "  for j in range(x1.shape[0]):\n",
        "    line = np.matmul(F, np.array([x2[j], y2[j], 1]))\n",
        "    temp = abs(np.matmul(np.array([x1[j], y1[j], 1]), line)) / sqrt(line[0]**2 + line[1]**2)\n",
        "    distances.append(temp)\n",
        "  distances = np.array(distances)\n",
        "  assert np.amin(distances) >= 0, str(np.amin(distances))+' is the min number'\n",
        "  distances[distances<=threshold] = -1\n",
        "  distances[distances>threshold] = 0\n",
        "  num_inliers = np.sum(distances) / -1\n",
        "  return num_inliers, distances\n",
        "\n",
        "  \n",
        "def computeF(x1, y1, x2, y2):\n",
        "  #  Function: compute fundamental matrix from corresponding points\n",
        "  A = []\n",
        "  for i in range(x1.shape[0]):\n",
        "    A.append([x1[i]*x2[i], x1[i]*y2[i], x1[i], y1[i]*x2[i], y1[i]*y2[i], y1[i], x2[i], y2[i], 1])\n",
        "  U, S, VT = np.linalg.svd(A)\n",
        "  f = VT[-1]\n",
        "  F = np.reshape(f, (3,3))\n",
        "  u, s, vt = np.linalg.svd(F)\n",
        "  s[-1] = 0\n",
        "  s = np.diag(s)\n",
        "  F = np.matmul(u, np.matmul(s, vt))\n",
        "  return F\n",
        "\n",
        "def gen_epi_line_and_plot(epi_line, x, y, img):\n",
        "  rows, cols, _ = img.shape\n",
        "  start1 = (0, int(-epi_line[2][0]/epi_line[1][0]))\n",
        "  x_ = cols-1\n",
        "  y_ = int(((-epi_line[0][0]*x_)-epi_line[2][0]) / epi_line[1][0])\n",
        "  end1 = (x_, y_)\n",
        "  img = cv2.line(img, start1, end1, (0, 255, 0), 1)\n",
        "  img = cv2.circle(img, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
        "  return img\n",
        "\n",
        "def plot_epi_lines(epi_line_1, epi_line_2, x_1, y_1, x_2, y_2, im1, im2, show_result):\n",
        "  im1 = gen_epi_line_and_plot(epi_line_1, x_1, y_1, im1)\n",
        "  im2 = gen_epi_line_and_plot(epi_line_2, x_2, y_2, im2)\n",
        "  if show_result:\n",
        "    combined_img = np.hstack((im1, im2))\n",
        "    cv2_imshow(combined_img)\n",
        "\n",
        "img1 = cv2.imread('/content/Part1_data/chapel00.png')\n",
        "img2 = cv2.imread('/content/Part1_data/chapel01.png')\n",
        "F, max_inlier_comb = ransacF(x1, y1, x2, y2)\n",
        "F_unit = F / np.sqrt(np.sum(np.square(F)))\n",
        "print(F_unit)\n",
        "rand_7_indices=[]\n",
        "while np.unique(rand_7_indices).shape[0] != 7:\n",
        "  rand_7_indices = (np.random.rand(7)*x1.shape[0]).astype(int)\n",
        "\n",
        "for rand_idx in rand_7_indices:\n",
        "  x_1 = x1[rand_idx]\n",
        "  y_1 = y1[rand_idx]\n",
        "  x_2 = x2[rand_idx]\n",
        "  y_2 = y2[rand_idx]\n",
        "  epi_line_1 = np.matmul(F, np.array([x_2, y_2, 1], dtype=object))\n",
        "  epi_line_2 = np.matmul(F.T, np.array([x_1, y_1, 1], dtype=object))\n",
        "  plot_epi_lines(epi_line_1, epi_line_2, x_1, y_1, x_2, y_2, img1, img2, rand_idx==rand_7_indices[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUvFYC17Bi5q"
      },
      "source": [
        "### Write-up\n",
        "<!-- *   Describe what test you used for deciding inlier vs. outlier.\n",
        "*   Display the estimated fundamental matrix F after normalizing to unit length\n",
        "*   Randomly select 7 sets of matching points. Plot the corresponding epipolar lines and the points on each image. Show the two images (with plotted points and lines) next to each other. -->\n",
        "\n",
        "<!-- *   Plot the outlier keypoints with green dots on top of the first image -->\n",
        "<!-- *   Randomly select 7 sets of matching points. Plot the corresponding epipolar lines ('g’) and the points (with 'r+’) on each image. Show the two images (with plotted points and lines) next to each other. -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JB8fYJCBI6B"
      },
      "source": [
        "- 1) Test used for deciding inlier vs. outlier.\n",
        "  - Given a pair of matches x1 & x2, I computed the epipolar line of x2 in image1 & found the distance of the point x1 from the above computed epipolar line in img1 and thresholded it to decide if the pair of matches is an outlier.\n",
        "\n",
        "- 2) Fundamental Matrix (after normalizing to unit length):\n",
        "\n",
        "  <img src=\"https://drive.google.com/uc?id=1OdJPrN4R5N9Q_Kdk-OBtv_cAnbt_EkKb\" width=\"400\"/>\n",
        "\n",
        "- 3) Epipolar Lines & associated points:\n",
        "\n",
        "  <img src=\"https://drive.google.com/uc?id=1BLWXQE0PlyWIvBNsqK_qhNRYkK9h7YSq\" width=\"800\"/>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pKARgqUEG9Nd",
        "f3j4FysdrPpj",
        "WhMdiMNjB9R7",
        "_EOoxrZurmYz"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}