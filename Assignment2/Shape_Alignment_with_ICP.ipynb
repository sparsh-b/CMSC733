{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "uvkyHmVv1Xe7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy_Iqu-qnIj3"
      },
      "outputs": [],
      "source": [
        "## Import necessary libraries here\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from scipy import ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import copy\n",
        "import os\n",
        "import time\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UurFy8hB5BeP"
      },
      "source": [
        "# Shape Alignment with the Point-to-point version of Iterative Closest Point Algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baagTPK5aa9r"
      },
      "source": [
        "- This problem involves aligning two sets of points using a global image transformation and return a transformation that maps non-zero points in $im1$ to non-zero points in $im2$.\n",
        "- This method is repeated to get better & better transformations.\n",
        "\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1qSrXkFvyG6rnzXBqJAYG9uqCOoMYSv3W\" width=\"1000\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWCfxrUA7LNb"
      },
      "source": [
        "## Data\n",
        "\n",
        "**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5aF6Biq7LvQ",
        "outputId": "775f8a5a-55d3-4ca0-ea4d-cea40c48d6d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18Px9uQyY1fGGyEAQhzt3h4yDQonU_Sgm\n",
            "To: /content/part2_images.zip\n",
            "\r  0% 0.00/78.4k [00:00<?, ?B/s]\r100% 78.4k/78.4k [00:00<00:00, 69.5MB/s]\n",
            "Archive:  /content/part2_images.zip\n",
            "   creating: /content/part2_images/\n",
            " extracting: /content/part2_images/Bone_1.png  \n",
            " extracting: /content/part2_images/elephant_1.png  \n",
            " extracting: /content/part2_images/brick_2.png  \n",
            " extracting: /content/part2_images/Heart_2.png  \n",
            " extracting: /content/part2_images/Bone_2.png  \n",
            "  inflating: /content/part2_images/elephant_2.png  \n",
            " extracting: /content/part2_images/brick_1.png  \n",
            " extracting: /content/part2_images/Heart_1.png  \n",
            "  inflating: /content/part2_images/device7_1.png  \n",
            "  inflating: /content/part2_images/device7_2.png  \n",
            " extracting: /content/part2_images/fork_2.png  \n",
            " extracting: /content/part2_images/turtle_2.png  \n",
            "  inflating: /content/part2_images/fork_1.png  \n",
            " extracting: /content/part2_images/turtle_1.png  \n",
            " extracting: /content/part2_images/butterfly_2.png  \n",
            " extracting: /content/part2_images/car_1.png  \n",
            " extracting: /content/part2_images/bottle_1.png  \n",
            " extracting: /content/part2_images/bat_2.png  \n",
            " extracting: /content/part2_images/jar_2.png  \n",
            "  inflating: /content/part2_images/hammer_1.png  \n",
            " extracting: /content/part2_images/carriage_2.png  \n",
            " extracting: /content/part2_images/bird_2.png  \n",
            " extracting: /content/part2_images/butterfly_1.png  \n",
            " extracting: /content/part2_images/car_2.png  \n",
            " extracting: /content/part2_images/bottle_2.png  \n",
            " extracting: /content/part2_images/jar_1.png  \n",
            " extracting: /content/part2_images/bat_1.png  \n",
            " extracting: /content/part2_images/hammer_2.png  \n",
            " extracting: /content/part2_images/carriage_1.png  \n",
            " extracting: /content/part2_images/bird_1.png  \n",
            " extracting: /content/part2_images/chicken_1.png  \n",
            " extracting: /content/part2_images/camel_2.png  \n",
            " extracting: /content/part2_images/horse_1.png  \n",
            " extracting: /content/part2_images/bell_1.png  \n",
            " extracting: /content/part2_images/children_1.png  \n",
            " extracting: /content/part2_images/cattle_2.png  \n",
            " extracting: /content/part2_images/cellular_phone_2.png  \n",
            " extracting: /content/part2_images/chicken_2.png  \n",
            " extracting: /content/part2_images/camel_1.png  \n",
            " extracting: /content/part2_images/horse_2.png  \n",
            " extracting: /content/part2_images/bell_2.png  \n",
            " extracting: /content/part2_images/children_2.png  \n",
            " extracting: /content/part2_images/cattle_1.png  \n",
            " extracting: /content/part2_images/cellular_phone_1.png  \n",
            " extracting: /content/part2_images/apple_1.png  \n",
            " extracting: /content/part2_images/face_1.png  \n",
            " extracting: /content/part2_images/dog_1.png  \n",
            " extracting: /content/part2_images/face_2.png  \n",
            " extracting: /content/part2_images/apple_2.png  \n",
            " extracting: /content/part2_images/dog_2.png  \n"
          ]
        }
      ],
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "!gdown 18Px9uQyY1fGGyEAQhzt3h4yDQonU_Sgm\n",
        "!unzip \"/content/part2_images.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqgb2YNJfQtV"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUgcCzJRAQJ1"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywdGq5E55thm"
      },
      "outputs": [],
      "source": [
        "def initialize(im1, mean1, mean2, scale_fact_1_to_2, im2, rows, cols):\n",
        "  '''\n",
        "  Apply translation & scaling to im1 as a way of initialization\n",
        "  '''\n",
        "  # Translation\n",
        "  old_img = copy.copy(im1)\n",
        "  im1 = (mean2-mean1) + im1\n",
        "\n",
        "  # Scaling\n",
        "  new_mean = np.mean(im1, axis=0)\n",
        "  im1 = im1 - new_mean\n",
        "  im1 = im1 * scale_fact_1_to_2\n",
        "  im1 = im1 + new_mean\n",
        "  im1[:, 0] = np.clip(im1[:, 0], 0, rows-1)\n",
        "  im1[:, 1] = np.clip(im1[:, 1], 0, cols-1)\n",
        "  return im1\n",
        "\n",
        "def find_NN(i, im2):\n",
        "  distance = 1e8\n",
        "  for j in im2:\n",
        "    curr_distance = np.linalg.norm(i-j)\n",
        "    if curr_distance < distance:\n",
        "      distance = curr_distance\n",
        "      nn = j\n",
        "  return nn\n",
        "\n",
        "def warp_image(im1, m1, m2, m3, m4, t1, t2, rows, cols):\n",
        "  warped_im1 = []\n",
        "  for i in im1:\n",
        "    warped_im1.append([np.clip(m1*i[0]+m2*i[1]+t1, 0, rows-1), np.clip(m3*i[0]+m4*i[1]+t2, 0, cols-1)])\n",
        "  return warped_im1\n",
        "\n",
        "def align_shape(im1, im2, num_iter=50, show_every_iter=False):\n",
        "  '''\n",
        "  im1: input edge image 1\n",
        "  im2: input edge image 2\n",
        "\n",
        "  Output: transformation T [3] x [3]\n",
        "  '''\n",
        "  orig_im2 = copy.copy(im2)\n",
        "  (rows, cols) = im1.shape\n",
        "  idx_grid = np.mgrid[0:rows, 0:cols]\n",
        "  idx_grid = np.swapaxes(idx_grid, 0, 1)\n",
        "  idx_grid = np.swapaxes(idx_grid, 1, 2)\n",
        "  im1 = idx_grid[im1==255] # Gives coordinates of pixels in (row, col) format\n",
        "  im2 = idx_grid[im2==255]\n",
        "  mean1 = np.mean(im1, axis=0)\n",
        "  mean2 = np.mean(im2, axis=0)\n",
        "  scale1 = np.std(im1, axis=0)\n",
        "  scale2 = np.std(im2, axis=0)\n",
        "  scale_fact_1_to_2 = scale2 / scale1\n",
        "  im1 = initialize(im1, mean1, mean2, scale_fact_1_to_2, im2, rows, cols)\n",
        "\n",
        "  for iter in range(num_iter):\n",
        "    matches = []\n",
        "    for i in im1:\n",
        "      nn_of_i = find_NN(i, im2)\n",
        "      matches.append([i, nn_of_i])\n",
        "    A = []\n",
        "    B = []\n",
        "    for match in matches:\n",
        "      x = match[0][0]\n",
        "      y = match[0][1]\n",
        "      x_dash = match[1][0]\n",
        "      y_dash = match[1][1]\n",
        "      A.append([x, y, 0, 0, 1, 0])\n",
        "      A.append([0, 0, x, y, 0, 1])\n",
        "      B.append(x_dash)\n",
        "      B.append(y_dash)\n",
        "    m1, m2, m3, m4, t1, t2 = np.linalg.lstsq(A, B, rcond=None)[0]\n",
        "    im1 = warp_image(im1, m1, m2, m3, m4, t1, t2, rows, cols)\n",
        "    if (show_every_iter):\n",
        "      test = copy.copy(orig_im2)\n",
        "      for i in range(len(im1)):\n",
        "        test[int(im1[i][0]), int(im1[i][1])] = 255\n",
        "      cv2_imshow(test)\n",
        "  return im1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itHJzXsKfSpQ"
      },
      "outputs": [],
      "source": [
        "def evalAlignment(aligned1, im2):\n",
        "  '''\n",
        "  Computes the error of the aligned image (aligned1) and im2, as the\n",
        "  average of the average minimum distance of a point in aligned1 to a point in im2\n",
        "  and the average minimum distance of a point in im2 to aligned1.\n",
        "  '''\n",
        "  d2 = ndimage.distance_transform_edt(1-im2) #distance transform\n",
        "  err1 = np.mean(np.mean(d2[aligned1 > 0]))\n",
        "  d1 = ndimage.distance_transform_edt(1-aligned1);\n",
        "  err2 = np.mean(np.mean(d2[im2 > 0]))\n",
        "  err = (err1+err2)/2;\n",
        "  return err\n",
        "\n",
        "def displayAlignment(im1, im2, aligned1, thick=False):\n",
        "  '''\n",
        "  Displays the alignment of im1 to im2\n",
        "     im1: first input image to alignment algorithm (im1(y, x)=1 if (y, x) \n",
        "      is an original point in the first image)\n",
        "     im2: second input image to alignment algorithm\n",
        "     aligned1: new1(y, x) = 1 iff (y, x) is a rounded transformed point from the first time \n",
        "     thick: true if a line should be thickened for display\n",
        "  ''' \n",
        "  if thick:\n",
        "    # for thick lines (looks better for final display)\n",
        "    dispim = np.concatenate((cv2.dilate(im1.astype('uint8'), np.ones((3,3), np.uint8), iterations=1), \\\n",
        "                             cv2.dilate(aligned1.astype('uint8'), np.ones((3,3), np.uint8), iterations=1), \\\n",
        "                             cv2.dilate(im2.astype('uint8'), np.ones((3,3), np.uint8), iterations=1)), axis=-1)\n",
        "  else:\n",
        "    # for thin lines (faster)\n",
        "    dispim = np.concatenate((im1, aligned1, im2), axis = -1)\n",
        "  return dispim\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vCuTHeShm41"
      },
      "outputs": [],
      "source": [
        "imgPath = '/content/part2_images/';\n",
        "\n",
        "objList = ['apple', 'bat', 'bell', 'bird', 'Bone', 'bottle', 'brick', \\\n",
        "    'butterfly', 'camel', 'car', 'carriage', 'cattle', 'cellular_phone', \\\n",
        "    'chicken', 'children', 'device7', 'dog', 'elephant', 'face', 'fork', 'hammer', \\\n",
        "    'Heart', 'horse', 'jar', 'turtle']\n",
        "\n",
        "numObj = len(objList)\n",
        "\n",
        "for idx in range(11, numObj):\n",
        "  start_time = time.time()\n",
        "  im1 = cv2.imread(imgPath+objList[idx]+'_1.png', 0)\n",
        "  im2 = cv2.imread(imgPath+objList[idx]+'_2.png', 0)\n",
        "  (rows, cols) = im1.shape\n",
        "\n",
        "  aligned_im1_coords = align_shape(im1, im2)\n",
        "  end_time = time.time()\n",
        "  aligned_im1_coords = np.array(aligned_im1_coords)\n",
        "  aligned_im1 = np.zeros((rows, cols))\n",
        "  for i in range(np.shape(aligned_im1_coords)[0]):\n",
        "    aligned_im1[int(aligned_im1_coords[i][0]), int(aligned_im1_coords[i][1])] = 255\n",
        "  print('Runtime for ', objList[idx], '= ', end_time - start_time, ' seconds')\n",
        "  error = evalAlignment(aligned_im1, im2)\n",
        "  dispim = displayAlignment(im1, im2, aligned_im1, thick=True)\n",
        "  print('Error for ', objList[idx], '= ', error)\n",
        "  cv2_imshow(dispim)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AmYt5Vu9BGq"
      },
      "source": [
        "## Write-up\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRUDQ9Xk5e3v"
      },
      "source": [
        "#### 1) Explanation of Algorithm, initialization & Transformation model:\n",
        "\n",
        "##### - Algorithm:\n",
        "- Firstly, the edge points in both the images are calculated (by storing the coordinates of the pixels whose value is 255).\n",
        "- Secondly, these arrays of edge points are used to generate an initial transformation as described in the next sub-section.\n",
        "- Then, the Iterative Closest Point algorithm is applied in the following way:\n",
        "  - Determine the match for a point in image1 by finding the point in image2 which has the smallest Euclidean distance. Repeat this for all the points in image1.\n",
        "  - Get the transformation that satisfies these pairs of matches as close as possible as described in the 'Transformation model' sub-section below.\n",
        "  - Using the estimated transformation matrix, warp all the points in image1.\n",
        "  - Repeat the above steps feeding the output of one iteration as the input for the next iteration.\n",
        "- The output of the final iteration gives the final version of image1 aligned with image2.\n",
        "\n",
        "##### - Initialization:\n",
        "  - The first image is translated & scaled in the following way to make it look closer to the second image.\n",
        "  - First, the difference in the centroids between both the images is calculated & all the points in image1 are translated by this value. Let's call this image `translated_img`.\n",
        "  - Then, the standard deviation of each image is calculated & the scale factor is defined as `std_dev of image2 / std_dev of image1`.\n",
        "  - Finally, scaling is performed by radially stretching (from centroid) every point in `translated_img` by this `scale factor`.\n",
        "  - <ins>Note</ins>: 'image' in this sub-section referes to the array of edge points in a picture.\n",
        "\n",
        "##### - Transformation model:\n",
        "  - An affine transformation model is used to fit the pairs of matches between both the images.\n",
        "  - This is done using Direct Linear transformation.\n",
        "  - A Least squares approach is used to find the parametres of the transformation.\n",
        "  - <ins>Note</ins>: 'image' in this sub-section refers to the array of edge points in a picture.\n",
        "\n",
        "#### 2) Results:\n",
        "- IMAGE 1 ----------------------------------- TRANSFORMATION APPLIED ON IMAGE 1 ------------------------ IMAGE 2\n",
        "- <img src=\"https://drive.google.com/uc?id=19IrJ3AsmIOTIHt-fVArm0QxqNOF6hlhc\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:194\n",
        "  - Error:174\n",
        "- <img src=\"https://drive.google.com/uc?id=106IkD29-eYkdbj-hKnsCFebqGlgKjwu-\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:1183\n",
        "  - Error:425\n",
        "- <img src=\"https://drive.google.com/uc?id=1M1tDu-_0yUv4-3E_GRUd8B44m4Nk8X8x\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:125\n",
        "  - Error:179\n",
        "- <img src=\"https://drive.google.com/uc?id=1HAGqeu1c-7OtRKgBff5ALAGFNLPmnwvi\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:469\n",
        "  - Error:221\n",
        "- <img src=\"https://drive.google.com/uc?id=1z9K5JhKtOJtCbEugL9OsHSfwaKfJrLCz\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:528\n",
        "  - Error:320\n",
        "- <img src=\"https://drive.google.com/uc?id=1Q-hvSrUirBOOO-2rlIG8eyIs2rCo8b3c\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:49\n",
        "  - Error:246\n",
        "- <img src=\"https://drive.google.com/uc?id=1BzhlGskNeLPRr-fS6u9PtwheGVIKjMDd\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:115\n",
        "  - Error:303\n",
        "- <img src=\"https://drive.google.com/uc?id=1Bu-wYZDRw_-Vg4fdV3wT1kKVZ_lGaBXc\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:464\n",
        "  - Error:212\n",
        "- <img src=\"https://drive.google.com/uc?id=1aDSvtY_TfkCEgBJ1KqCMYyCR-adaUX8Y\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:868\n",
        "  - Error:269\n",
        "- <img src=\"https://drive.google.com/uc?id=1KPNNB3MMbnp9dn4ETaHhXgPsb7ewfcAp\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:91\n",
        "  - Error:242\n",
        "- <img src=\"https://drive.google.com/uc?id=1U0eas9COqcj2R7Zragppsb-BpSLdOrdz\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:211\n",
        "  - Error:284\n",
        "- <img src=\"https://drive.google.com/uc?id=1YzWMeo0QmWVkgCWzwWMU-L7pv06cFEm2\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:2742\n",
        "  - Error:392\n",
        "- <img src=\"https://drive.google.com/uc?id=1c8gtSRW2c6HF3D7-oiw5MZknJ18-kKDv\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:360\n",
        "  - Error:258\n",
        "- <img src=\"https://drive.google.com/uc?id=1FbAgczb6bzJ-nuzvC1xIRWBSNrYnjHZO\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:237\n",
        "  - Error:144\n",
        "- <img src=\"https://drive.google.com/uc?id=1T4w99rLLFI-e37_lseIOga-9zWuuzEiX\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:63\n",
        "  - Error:155\n",
        "- <img src=\"https://drive.google.com/uc?id=1aUcR-J3ViBLqDU2QBjBI7_rwqex4FHzh\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:5258\n",
        "  - Error:382\n",
        "- <img src=\"https://drive.google.com/uc?id=1Jyw2tEcqXja4YiWf6-7qV0vWRS9xp2-f\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:2141\n",
        "  - Error:351\n",
        "- <img src=\"https://drive.google.com/uc?id=1V3GtwterQUnx1wcCqVizxdCObSQgsPrQ\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:4196\n",
        "  - Error:562\n",
        "- <img src=\"https://drive.google.com/uc?id=1gpmsr3IOw91QtGz4u-ueMLH_YXwXUutm\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:222\n",
        "  - Error:232\n",
        "- <img src=\"https://drive.google.com/uc?id=1wHkWNe9WuflBibGXfP-PrgZyCS9NhUY_\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:1409\n",
        "  - Error:357\n",
        "- <img src=\"https://drive.google.com/uc?id=1V4lUww35Z6kerzIcy2JsJJLb0_JZ8Cbp\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:151\n",
        "  - Error:156\n",
        "- <img src=\"https://drive.google.com/uc?id=1l6YYA8EeLd2pPNLFM_Gfgi6qs5rW0rQp\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:677\n",
        "  - Error:311\n",
        "- <img src=\"https://drive.google.com/uc?id=1bYlV3GaT-yhm_kB9gMM0vPKaS30mHlvb\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:4387\n",
        "  - Error:492\n",
        "- <img src=\"https://drive.google.com/uc?id=1pXpbBho3Oq9pKGPypzebZVXechqKUNTa\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:1463\n",
        "  - Error:386\n",
        "- <img src=\"https://drive.google.com/uc?id=1hSmUT9s_iOAknjDx7peMoZK4vl4iqwQE\" align=\"center\"/>\n",
        "\n",
        "  - Runtime:400\n",
        "  - Error:250\n",
        "\n",
        "<ins>Note</ins>: The above runtimes are in seconds."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qWCfxrUA7LNb",
        "ZDy-8Y7Oj7kJ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}